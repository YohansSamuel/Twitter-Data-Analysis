{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:green'> Task 3 : Data Exploration & Preprocessing, Topic Modeling & Sentiment Analysis</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the csv file generated from clean_tweets_dataframe.py\n",
    "tweets_df = pd.read_csv(\"data/clean_processed_tweet_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the first 5 rows from our dataset\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display dataframe information\n",
    "tweets_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check null values\n",
    "tweets_df.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape of the dataframe\n",
    "tweets_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show columns of the dataframe\n",
    "tweets_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop empty values\n",
    "tweets_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets_df[\"source\"] = tweets_df[\"source\"].str.replace(r\"(\\s*\\<.*?\\>\\s*)\", \" \").str.strip()\n",
    "#tweets_df['Text'] = tweets_df['source'].str.replace(r\"\\<.*\\>?\",\"\")\n",
    "tweets_df['Text'] = tweets_df['Text'].str.replace(r\"\\(<^()>*\\)\", \"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize polarity column using piechart and barchart\n",
    "# Pie chart, where the slices will be ordered and plotted counter-clockwise:\n",
    "labels = ['neutral', 'positive', 'negative']\n",
    "\n",
    "neutral_count =  len(tweets_df[tweets_df['polarity'] > 0])\n",
    "positive_count = len(tweets_df[tweets_df['polarity'] == 0])\n",
    "negative_count = len(tweets_df[tweets_df['polarity'] <0])\n",
    "sizes = [neutral_count, positive_count, negative_count]\n",
    "# Create a figure for 2 subplots (1 row, 2 columns)\n",
    "fig, ax = plt.subplots(1, 2, figsize = (10,4))\n",
    "\n",
    "# Create a bar plot of score column\n",
    "ax[0].bar(x=labels, height=[neutral_count, positive_count, negative_count], color='orange')\n",
    "ax[0].set_title('Barchart of score column')\n",
    "ax[0].set_xticklabels(labels, rotation=90)\n",
    "\n",
    "# Create a pie chart of score column based on neutral, positive or negative\n",
    "\n",
    "ax[1].pie(sizes,labels=labels, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90)\n",
    "ax[1].set_title('Piechart of score column')\n",
    "ax[1].legend(labels)\n",
    "\n",
    "# Add a title to the Figure\n",
    "fig.suptitle('Score column plots')\n",
    "\n",
    "# Show the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new column named clean_text to store cleaned original text\n",
    "tweets_df.insert(4,column = 'clean_text',value = tweets_df['original_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new column named sentimnt to where the text is positive,negative or neutral\n",
    "# tweets_df.insert(7,column = 'sentiment',value = tweets_df['polarity'])\n",
    "tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "tweets_df = tweets_df[['original_text','clean_text','polarity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_category (polarity):\n",
    "    if polarity > 0:\n",
    "        return 'positive'\n",
    "    if polarity < 0:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score= pd.Series([text_category(row_value) for row_value in tweets_df['polarity']])\n",
    "tweets_df = pd.concat([tweets_df, score.rename('sentiment')], axis=1)\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gensim\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim import corpora\n",
    "from pprint import pprint\n",
    "import string\n",
    "import re\n",
    "import emoji\n",
    "import nltk\n",
    "#nltk.download('words')\n",
    "words = set(nltk.corpus.words.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cleaner(tweet):\n",
    "    tweet = re.sub(\"@[A-Za-z0-9]+\",\"\",tweet) #Remove @ sign\n",
    "    tweet = re.sub(r\"(?:\\@|http?\\://|https?\\://|www)\\S+\", \"\", tweet) #Remove http links\n",
    "    tweet = \" \".join(tweet.split())\n",
    "    tweet = ''.join(c for c in tweet if c not in emoji.UNICODE_EMOJI) #Remove Emojis\n",
    "    tweet = tweet.replace(\"#\", \"\").replace(\"_\", \" \") #Remove hashtag sign but keep the text\n",
    "    tweet = \" \".join(w for w in nltk.wordpunct_tokenize(tweet) \\\n",
    "         if w.lower() in words or not w.isalpha())\n",
    "    return tweet\n",
    "\n",
    "tweets_df['clean_text'] = tweets_df['original_text'].map(lambda x: cleaner(x))\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrepareData:\n",
    "  def __init__(self,df):\n",
    "    self.df=df\n",
    "    \n",
    "  def preprocess_data(self):\n",
    "    #tweets_df = self.df.loc[self.df['lang'] ==\"en\"]\n",
    "\n",
    "    \n",
    "    #text Preprocessing\n",
    "    tweets_df['clean_text']=tweets_df['clean_text'].astype(str)\n",
    "    tweets_df['clean_text'] = tweets_df['clean_text'].apply(lambda x: x.lower())\n",
    "    tweets_df['clean_text']= tweets_df['clean_text'].apply(lambda x: x.translate(str.maketrans(' ', ' ', string.punctuation)))\n",
    "    \n",
    "    #Converting tweets to list of words For feature engineering\n",
    "    sentence_list = [tweet for tweet in tweets_df['clean_text']]\n",
    "    word_list = [sent.split() for sent in sentence_list]\n",
    "    # print(word_list)\n",
    "\n",
    "    #Create dictionary which contains Id and word \n",
    "    word_to_id = corpora.Dictionary(word_list) #generate unique tokens\n",
    "    #  we can see the word to unique integer mapping\n",
    "    # print(word_to_id.token2id)\n",
    "    # using bag of words(bow), we create a corpus that contains the word id and its frequency in each document.\n",
    "    corpus_1= [word_to_id.doc2bow(tweet) for tweet in word_list]\n",
    "    # TFIDF\n",
    "\n",
    "    return tweets_df['clean_text'],word_list, word_to_id, corpus_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PrepareData_obj=PrepareData(tweets_df)\n",
    "tweets_df['clean_text'],word_list ,id2word,corpus=PrepareData_obj.preprocess_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(corpus)\n",
    "tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_words = [[(id2word[id], count) for id, count in line] for line in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(id_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3 Topic Modelling using Latent Dirichlet Allocation(LDA)\n",
    "#### The purpose of LDA is mapping each teweets in our corpus to a set of topics which covers a good deal of the words in the tweet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=5, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.072*\"the\" + 0.052*\"is\" + 0.042*\"china\" + 0.033*\"this\" + 0.032*\"in\" + '\n",
      "  '0.028*\"of\" + 0.028*\"s\" + 0.026*\"…\" + 0.024*\"that\" + 0.022*\"on\"'),\n",
      " (1,\n",
      "  '0.053*\"to\" + 0.037*\"…\" + 0.036*\"the\" + 0.030*\"it\" + 0.024*\"of\" + 0.023*\"s\" '\n",
      "  '+ 0.022*\"not\" + 0.018*\"island\" + 0.018*\"in\" + 0.017*\"we\"'),\n",
      " (2,\n",
      "  '0.069*\"on\" + 0.043*\"china\" + 0.042*\"’\" + 0.039*\"s\" + 0.036*\"of\" + 0.036*\"a\" '\n",
      "  '+ 0.035*\"…\" + 0.024*\"missile\" + 0.023*\"military\" + 0.021*\"an\"'),\n",
      " (3,\n",
      "  '0.042*\"part\" + 0.038*\"out\" + 0.033*\"speaker\" + 0.032*\"t\" + 0.030*\"’\" + '\n",
      "  '0.028*\"for\" + 0.027*\"their\" + 0.023*\"…\" + 0.022*\"5\" + 0.020*\"and\"'),\n",
      " (4,\n",
      "  '0.075*\"the\" + 0.062*\"to\" + 0.042*\"…\" + 0.041*\"s\" + 0.038*\"china\" + '\n",
      "  '0.035*\"and\" + 0.029*\"us\" + 0.024*\"visit\" + 0.022*\"a\" + 0.021*\"of\"')]\n"
     ]
    }
   ],
   "source": [
    "pprint(lda_model.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  [('the', 0.0720394),\n",
      "   ('is', 0.051672734),\n",
      "   ('china', 0.04224037),\n",
      "   ('this', 0.033075012),\n",
      "   ('in', 0.032355797),\n",
      "   ('of', 0.027817756),\n",
      "   ('s', 0.027659101),\n",
      "   ('…', 0.026197946),\n",
      "   ('that', 0.023988543),\n",
      "   ('on', 0.021984821)]),\n",
      " (1,\n",
      "  [('to', 0.052805908),\n",
      "   ('…', 0.03654342),\n",
      "   ('the', 0.03555156),\n",
      "   ('it', 0.030056885),\n",
      "   ('of', 0.024076967),\n",
      "   ('s', 0.02344202),\n",
      "   ('not', 0.022206457),\n",
      "   ('island', 0.018373588),\n",
      "   ('in', 0.017870707),\n",
      "   ('we', 0.016598973)]),\n",
      " (2,\n",
      "  [('on', 0.06912865),\n",
      "   ('china', 0.043411385),\n",
      "   ('’', 0.04203578),\n",
      "   ('s', 0.039337996),\n",
      "   ('of', 0.035956223),\n",
      "   ('a', 0.03587063),\n",
      "   ('…', 0.035150617),\n",
      "   ('missile', 0.024428003),\n",
      "   ('military', 0.023469845),\n",
      "   ('an', 0.020680407)]),\n",
      " (3,\n",
      "  [('part', 0.041534945),\n",
      "   ('out', 0.038097065),\n",
      "   ('speaker', 0.03316909),\n",
      "   ('t', 0.031809844),\n",
      "   ('’', 0.029987387),\n",
      "   ('for', 0.027728545),\n",
      "   ('their', 0.026711373),\n",
      "   ('…', 0.02333698),\n",
      "   ('5', 0.02189074),\n",
      "   ('and', 0.019878184)]),\n",
      " (4,\n",
      "  [('the', 0.07540812),\n",
      "   ('to', 0.062312294),\n",
      "   ('…', 0.04226574),\n",
      "   ('s', 0.04094148),\n",
      "   ('china', 0.038096923),\n",
      "   ('and', 0.035040535),\n",
      "   ('us', 0.029488726),\n",
      "   ('visit', 0.02444664),\n",
      "   ('a', 0.02151323),\n",
      "   ('of', 0.02108042)])]\n"
     ]
    }
   ],
   "source": [
    "pprint(lda_model.show_topics(formatted=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compute Perplexity\n",
    "\n",
    "# #It's a measure of how good the model is. The lower the better. Perplexity is a negative value\n",
    "# print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  \n",
    "# doc_lda = lda_model[corpus]\n",
    "\n",
    "\n",
    "# # Compute Coherence Score\n",
    "# coherence_model_lda = CoherenceModel(model=lda_model, texts=word_list, dictionary=id2word, coherence='c_v')\n",
    "# coherence_lda = coherence_model_lda.get_coherence()\n",
    "# print('\\n Ldamodel Coherence Score/Accuracy on Tweets: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pyLDAvis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pickle \n",
    "import pyLDAvis\n",
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "LDAvis_prepared = gensimvis.prepare(lda_model, corpus, id2word)\n",
    "LDAvis_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_string = ','.join(list(tweets_df['clean_text'].values))\n",
    "\n",
    "wordcloud = WordCloud(background_color=\"white\", max_words=1000, contour_width=3, contour_color='steelblue')\n",
    "\n",
    "wordcloud.generate(long_string)\n",
    "\n",
    "# Visualize the word cloud\n",
    "wordcloud.to_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4 Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import re\n",
    "import nltk \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot params\n",
    "# plot_size = plt.rcParams[\"figure.figsize\"] \n",
    "# plot_size[0] = 8\n",
    "# plot_size[1] = 6\n",
    "# plt.rcParams[\"figure.figsize\"] = plot_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # number of tweets for each airline\n",
    "# sns.set(rc={'figure.figsize':(14,10)})\n",
    "# tweets_df.polarity.value_counts().plot(kind='pie', autopct='%1.0f%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Distribution of sentiments across all the tweets.\n",
    "# sns.set(rc={'figure.figsize':(14,10)})\n",
    "# tweets_df.sentiment.value_counts().plot(kind='pie', autopct='%1.0f%%', colors=[\"red\", \"yellow\", \"green\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.set(rc={'figure.figsize':(12,8)})\n",
    "# sentiment = tweets_df.groupby(['Polarity', 'Sentiment']).sentiment.count().unstack()\n",
    "# sentiment.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Selecting the feature and the label\n",
    "# features = tweets_df.iloc[:, 10].values\n",
    "# labels = tweets_df.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Data Cleaning using regular expression\n",
    "# processed_features = []\n",
    "\n",
    "# for sentence in range(0, len(features)):\n",
    "#     # Remove all the special characters\n",
    "#     processed_feature = re.sub(r'\\W', ' ', str(features[sentence]))\n",
    "\n",
    "#     # remove all single characters\n",
    "#     processed_feature= re.sub(r'\\s+[a-zA-Z]\\s+', ' ', processed_feature)\n",
    "\n",
    "#     # Remove single characters from the start\n",
    "#     processed_feature = re.sub(r'\\^[a-zA-Z]\\s+', ' ', processed_feature) \n",
    "\n",
    "#     # Substituting multiple spaces with single space\n",
    "#     processed_feature = re.sub(r'\\s+', ' ', processed_feature, flags=re.I)\n",
    "\n",
    "#     # Removing prefixed 'b'\n",
    "#     processed_feature = re.sub(r'^b\\s+', '', processed_feature)\n",
    "\n",
    "#     # Converting to Lowercase\n",
    "#     processed_feature = processed_feature.lower()\n",
    "\n",
    "#     processed_features.append(processed_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import SGDClassifier\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "# from nltk.corpus import stopwords\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# vectorizer = TfidfVectorizer (max_features=2500, min_df=7, max_df=0.8, stop_words=stopwords.words('english'))\n",
    "# processed_features_vectorized = vectorizer.fit_transform(processed_features).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(processed_features_vectorized, labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# text_classifier = RandomForestClassifier(n_estimators=200, random_state=0)\n",
    "# text_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = text_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tweets_df['clean_text']\n",
    "y = tweets_df['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.size)\n",
    "print(X_test.size)\n",
    "print(y_train.size)\n",
    "print(y_test.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the input\n",
    "clf = make_pipeline(StandardScaler(), SGDClassifier(max_iter=1000, tol=1e-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(1,2)\n",
    "#X_train = X_train.replace(np.nan, '', regex=True)\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "X_train_counts = X_train_counts.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train_counts, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.replace(np.nan, '', regex=True)\n",
    "# use transform not fit_transform\n",
    "X_test_counts = count_vect.transform(X_test)\n",
    "X_test_counts = X_test_counts.toarray()\n",
    "# prediction = clf.prevaluedict(X_test_counts)\n",
    "prediction = clf.predict(X_test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making prediction\n",
    "prediction = clf.predict(X_test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(prediction == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_confusion_matrix(clf, X_test, y_test, display_labels = ['negative', 'positive','neutral'])\n",
    "# plt.suptitle('Confusion Matrix')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a492b5279fe2e495c47ca4f6b152dc65c94fc5038b5e698174c22ffedef5d685"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
